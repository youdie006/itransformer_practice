#!/bin/bash

# macOS MPSë¥¼ ìœ„í•œ iTransformer í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
# PyTorch MPS ë°±ì—”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ Apple Silicon GPU ê°€ì† í™œìš©

echo "ðŸŽ Setting up iTransformer environment for macOS MPS..."

# conda í™˜ê²½ ìƒì„± (Python 3.9 ê¶Œìž¥ - MPS ì•ˆì •ì„±)
echo "ðŸ“¦ Creating conda environment: itransformer_mps"
conda create -n itransformer_mps python=3.9 -y

# í™˜ê²½ í™œì„±í™”
echo "ðŸ”§ Activating environment..."
conda activate itransformer_mps

# macOS MPS ì§€ì› PyTorch ì„¤ì¹˜ (nightly ë˜ëŠ” 2.0+ ë²„ì „)
echo "âš¡ Installing PyTorch with MPS support..."
conda install pytorch torchvision torchaudio -c pytorch -y

# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
echo "ðŸ“š Installing basic packages..."
conda install pandas scikit-learn numpy matplotlib -c conda-forge -y

# ì¶”ê°€ í•„ìˆ˜ íŒ¨í‚¤ì§€
echo "ðŸ”§ Installing additional packages..."
pip install reformer-pytorch==1.4.4
pip install einops  # reformer-pytorch ì˜ì¡´ì„±
pip install seaborn  # ì‹œê°í™”
pip install tqdm     # ì§„í–‰ë¥  í‘œì‹œ

# MPS ê°€ìš©ì„± í™•ì¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
echo "âœ… Creating MPS availability check script..."
cat > check_mps.py << 'EOF'
import torch
import sys

print("ðŸŽ macOS MPS Availability Check")
print("=" * 40)
print(f"PyTorch version: {torch.__version__}")
print(f"Python version: {sys.version}")

if torch.backends.mps.is_available():
    print("âœ… MPS backend is available!")
    
    # MPS ìž¥ì¹˜ ìƒì„± í…ŒìŠ¤íŠ¸
    try:
        device = torch.device("mps")
        x = torch.randn(100, 100, device=device)
        y = torch.randn(100, 100, device=device)
        z = torch.matmul(x, y)
        print("âœ… MPS device test passed!")
        print(f"   Device: {device}")
        print(f"   Tensor shape: {z.shape}")
        print(f"   Memory allocated: {torch.mps.current_allocated_memory()/1024/1024:.2f} MB")
    except Exception as e:
        print(f"âŒ MPS device test failed: {e}")
        
else:
    print("âŒ MPS backend is not available")
    print("   Fallback to CPU will be used")

# ì¶”ì²œ ì„¤ì • ì¶œë ¥
print("\nðŸ”§ Recommended settings for iTransformer:")
print("   - Use smaller batch sizes (16-32) for MPS")
print("   - Monitor memory usage with torch.mps.current_allocated_memory()")
print("   - Set device = torch.device('mps') in your code")
EOF

echo "ðŸŽ¯ Running MPS availability check..."
python check_mps.py

echo ""
echo "ðŸŽ‰ Setup complete!"
echo ""
echo "To use this environment:"
echo "  conda activate itransformer_mps"
echo "  cd /Users/manon/CursorProject/iTransformer_practice"
echo "  python iTransformer_Study_Guide.py"
echo ""
echo "ðŸ’¡ Tips for MPS usage:"
echo "  - MPS is optimized for Apple Silicon (M1/M2/M3)"
echo "  - Use smaller batch sizes compared to CUDA"
echo "  - Monitor GPU memory with Activity Monitor"
echo "  - Some operations may fall back to CPU automatically"